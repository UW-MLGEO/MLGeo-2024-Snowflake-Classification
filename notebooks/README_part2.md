In this assignment, classic machine learning models were tested in the snowflake dataset to evaluate how well they would be able to classify the 11 different types identified. In all cases, PCA was employed to reduce the dimensionality of the data. After that, several Gaussian Mixture and K-Means clustering models were used. Their effectiveness was evaluated, in addition to their robustness by varying the random seeds involved. The auto-ML framework PyCaret was then used to test many classic machine learning models, and using the best-performing models according to its analysis, hyperparameter tuning was conducted. Cross-validation was implemented, and from there the models were evaluated using their accuracy, precision, recall, and F1 score. Finally, a more comprehensive time-based analysis was performed. All tools needed to replicate this are already included in the repository and the notebooks themselves.

Clustering proved to be an ineffective method for classifying the images, as cluster sizes and silhouette scores were inconsistent and low. Despite this, the models showed robustness as they proved to yield consistent results regardless of the initial random seed. As for classic ML, PyCaret determined that Random Forest, Extra Trees, Gradient Boosting, Light Gradient Boosting, and Logistic Regression were the most effective in classifying the images. However, model performance was poor, as accuracy, precision, recall, and F1 scores were considerably low. Ensemble learning was then used with hopes of improving these results, and though promising, these proved to be not much better as the accuracy and loss curves showed that they were especially affected by overfitting. The final runtime analysis proposed the Extra Trees classifier as the most efficient algorithm, but computational concerns such as memory usage, scalability and the lack of optimization made this unclear. Given these disappointing results, the next logical step would be exploring deep learning and whether it may improve these findings.


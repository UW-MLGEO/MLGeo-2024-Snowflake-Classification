{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Architecture Exploration and Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the `data_EDA_and_CML_benchmarking.ipynb` notebook for parts 1 and 2, which include the deep learning dataset preparation and CML benchmarking, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model Architecture Exploration: Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall, the performances of the initial four deep learning models implemented in the `data_EDA_and_CML_benchmarking.ipynb` notebook, which included FCN, CNN, ResNet, and RNN, were poor. Among them, the CNN had the highest accuracy, exceeding 25%. While this value is still low, we will focus on implementing architectures that utilize CNNs, focusing on the three architectures listed below:  \n",
    "\n",
    "1. VGG16 with Fine-Tuning (a deep CNN)\n",
    "* *Why?* A VGG16 is a deep CNN with 16 layers that excels at deep feature extraction, effectively capturing complex visual features through small 3x3 convolutional filters. By using pre-trained weights on ImageNet and fine-tuning them on the `PHIPS_CrystalHabitAI_Dataset.nc` image dataset, VGG16 can adapt to our specific classification task, improving performance even with limited data, as the `PHIPS_CrystalHabitAI_Dataset.nc` image dataset is relatively small. The VGG16's depth and fine-tuning capabilities help overcome the low accuracy of initial models by learning more intricate patterns specific to our ice crystal images.\n",
    "\n",
    "2. InceptionV3 (a different variation of a deep CNN)\n",
    "* *Why?* This architecture excels at multi-scale feature learning, utilizing Inception modules to process multiple convolutional filter sizes in parallel, capturing visual information at different scales within the same layer. Despite its depth, InceptionV3 is computationally efficient due to techniques like factorized convolutions and dimension reductions, making it suitable for complex datasets without excessive computational cost. Its advanced architecture can extract richer and more diverse features than simpler models, potentially leading to significant improvements in classification accuracy on the `PHIPS_CrystalHabitAI_Dataset.nc` image dataset.\n",
    "\n",
    "3. Convolutional Recurrent Neural Network (CRNN) with Attention Mechanism (a hyrbid of CNN and RNN)\n",
    "* *Why?* CRNN integrates Convolutional Neural Networks for spatial feature extraction with Recurrent Neural Networks (like LSTM or GRU) to capture sequential or temporal dependencies in the data. Incorporating attention layers enables the model to focus on the most relevant parts of the input images, enhancing its ability to learn important features and improving classification results. Lastly, this architecture offers a novel solution that goes beyond standard models, potentially capturing complex patterns and relationships in our ice crystal images that previous models may have missed.\n",
    "\n",
    "#### By using these DL architectures, we will address the low performance of the initial DL models by leveraging deeper networks, advanced feature extraction techniques, and innovative combinations of neural network types tailored to our image classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3.2 Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Flatten, Conv2D, MaxPooling2D, \n",
    "                                     GlobalAveragePooling2D, Input, SimpleRNN, LSTM, TimeDistributed, \n",
    "                                     Bidirectional, Attention)\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.preprocessing.image import smart_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn for metrics\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                             f1_score, precision_score, recall_score, mean_squared_error, roc_curve, auc)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Data Loading and Preprocessing\n",
    "##### organized using a `DatasetLoader` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for loading and preprocessing the dataset\n",
    "class DatasetLoader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load the dataset using xarray\n",
    "        ds = xr.open_dataset(self.file_path)\n",
    "        images = ds['image_array'].values  # Shape: (samples, height, width)\n",
    "        labels = ds['label'].values        # Shape: (samples,)\n",
    "        return images, labels\n",
    "\n",
    "    def preprocess_data(self, images, labels):\n",
    "        # Encode string labels into integers\n",
    "        label_encoder = LabelEncoder()\n",
    "        labels_encoded = label_encoder.fit_transform(labels)\n",
    "        num_classes = len(np.unique(labels_encoded))\n",
    "\n",
    "        # One-hot encode the labels\n",
    "        labels_one_hot = to_categorical(labels_encoded, num_classes)\n",
    "\n",
    "        # Expand dimensions of images for channels (grayscale images)\n",
    "        images_expanded = np.expand_dims(images, axis=-1)  # Shape: (samples, height, width, 1)\n",
    "\n",
    "        # Normalize images to [0, 1]\n",
    "        images_normalized = images_expanded / 255.0\n",
    "\n",
    "        return images_normalized, labels_one_hot, labels_encoded, num_classes, label_encoder\n",
    "\n",
    "    def split_data(self, images, labels_encoded, labels_one_hot):\n",
    "        # Split data into training, validation, and test sets\n",
    "        X_train, X_temp, y_train_encoded, y_temp_encoded, y_train_one_hot, y_temp_one_hot = train_test_split(\n",
    "            images, labels_encoded, labels_one_hot, test_size=0.2, random_state=42, stratify=labels_encoded)\n",
    "        X_val, X_test, y_val_encoded, y_test_encoded, y_val_one_hot, y_test_one_hot = train_test_split(\n",
    "            X_temp, y_temp_encoded, y_temp_one_hot, test_size=0.5, random_state=42, stratify=y_temp_encoded)\n",
    "\n",
    "        return (X_train, y_train_encoded, y_train_one_hot), \\\n",
    "               (X_val, y_val_encoded, y_val_one_hot), \\\n",
    "               (X_test, y_test_encoded, y_test_one_hot)\n",
    "\n",
    "# Instantiate the DatasetLoader and load the data\n",
    "data_loader = DatasetLoader('/Users/valeriagarcia/Desktop/ESS569_Snowflake_Classification/PHIPS_CrystalHabitAI_Dataset.nc')\n",
    "images, labels = data_loader.load_data()\n",
    "images, labels_one_hot, labels_encoded, num_classes, label_encoder = data_loader.preprocess_data(images, labels)\n",
    "(X_train, y_train_encoded, y_train_one_hot), \\\n",
    "(X_val, y_val_encoded, y_val_one_hot), \\\n",
    "(X_test, y_test_encoded, y_test_one_hot) = data_loader.split_data(images, labels_encoded, labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Data Augmentation\n",
    "##### Here, we create a data augmentation generator (`train_datagen`) for the training data that applies random transformations—including rotations up to 20 degrees, horizontal and vertical shifts up to 10% of the image size, horizontal and vertical flips, zooms up to 10%—to enhance the diversity of the dataset during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0,  # Images are already normalized\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# No augmentation for validation and test data, only rescaling\n",
    "val_datagen = ImageDataGenerator(rescale=1.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train_one_hot, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val_one_hot, batch_size=32)\n",
    "test_generator = test_datagen.flow(X_test, y_test_one_hot, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Custom Physics-Informed Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impacts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

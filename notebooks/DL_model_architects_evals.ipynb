{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Architecture Exploration and Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the `data_EDA_and_CML_benchmarking.ipynb` notebook for parts 1 and 2, which include the deep learning dataset preparation and CML benchmarking, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model Architecture Exploration: Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall, the performances of the initial four deep learning models implemented in the `data_EDA_and_CML_benchmarking.ipynb` notebook, which included FCN, CNN, ResNet, and RNN, were poor. Among them, the CNN had the highest accuracy, exceeding 25%. While this value is still low, we will focus on implementing architectures that utilize CNNs, focusing on the three architectures listed below:  \n",
    "\n",
    "1. VGG16 with Fine-Tuning (a deep CNN)\n",
    "* *Why?* A VGG16 is a deep CNN with 16 layers that excels at deep feature extraction, effectively capturing complex visual features through small 3x3 convolutional filters. By using pre-trained weights on ImageNet and fine-tuning them on the `PHIPS_CrystalHabitAI_Dataset.nc` image dataset, VGG16 can adapt to our specific classification task, improving performance even with limited data, as the `PHIPS_CrystalHabitAI_Dataset.nc` image dataset is relatively small. The VGG16's depth and fine-tuning capabilities help overcome the low accuracy of initial models by learning more intricate patterns specific to our ice crystal images.\n",
    "\n",
    "2. InceptionV3 (a different variation of a deep CNN)\n",
    "* *Why?* This architecture excels at multi-scale feature learning, utilizing Inception modules to process multiple convolutional filter sizes in parallel, capturing visual information at different scales within the same layer. Despite its depth, InceptionV3 is computationally efficient due to techniques like factorized convolutions and dimension reductions, making it suitable for complex datasets without excessive computational cost. Its advanced architecture can extract richer and more diverse features than simpler models, potentially leading to significant improvements in classification accuracy on the `PHIPS_CrystalHabitAI_Dataset.nc` image dataset.\n",
    "\n",
    "3. Convolutional Recurrent Neural Network (CRNN) with Attention Mechanism (a hyrbid of CNN and RNN)\n",
    "* *Why?* CRNN integrates Convolutional Neural Networks for spatial feature extraction with Recurrent Neural Networks (like LSTM or GRU) to capture sequential or temporal dependencies in the data. Incorporating attention layers enables the model to focus on the most relevant parts of the input images, enhancing its ability to learn important features and improving classification results. Lastly, this architecture offers a novel solution that goes beyond standard models, potentially capturing complex patterns and relationships in our ice crystal images that previous models may have missed.\n",
    "\n",
    "#### By using these DL architectures, we will address the low performance of the initial DL models by leveraging deeper networks, advanced feature extraction techniques, and innovative combinations of neural network types tailored to our image classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3.2 Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Flatten, Conv2D, MaxPooling2D, \n",
    "                                     GlobalAveragePooling2D, Input, SimpleRNN, LSTM, TimeDistributed, \n",
    "                                     Bidirectional, Attention)\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "from tensorflow.keras.layers import Concatenate, Resizing, Reshape, Permute, Multiply, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn for metrics\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                             f1_score, precision_score, recall_score, mean_squared_error, roc_curve, auc)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Data Loading and Preprocessing\n",
    "##### organized using a `DatasetLoader` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for loading and preprocessing the dataset\n",
    "class DatasetLoader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load the dataset using xarray\n",
    "        ds = xr.open_dataset(self.file_path)\n",
    "        images = ds['image_array'].values  # Shape: (samples, height, width)\n",
    "        labels = ds['label'].values        # Shape: (samples,)\n",
    "        temps = ds['temperature'].values   # Shape: (samples,)\n",
    "        return images, labels, temps\n",
    "\n",
    "    def preprocess_data(self, images, labels):\n",
    "        # Encode string labels into integers\n",
    "        label_encoder = LabelEncoder()\n",
    "        labels_encoded = label_encoder.fit_transform(labels)\n",
    "        num_classes = len(np.unique(labels_encoded))\n",
    "\n",
    "        # One-hot encode the labels\n",
    "        labels_one_hot = to_categorical(labels_encoded, num_classes)\n",
    "\n",
    "        # Expand dimensions of images for channels (grayscale images)\n",
    "        images_expanded = np.expand_dims(images, axis=-1)  # Shape: (samples, height, width, 1)\n",
    "\n",
    "        # Normalize images to [0, 1]\n",
    "        images_normalized = images_expanded / 255.0\n",
    "\n",
    "        return images_normalized, labels_one_hot, labels_encoded, num_classes, label_encoder\n",
    "\n",
    "    def split_data(self, images, labels_encoded, labels_one_hot):\n",
    "        # Split data into training, validation, and test sets\n",
    "        X_train, X_temp, y_train_encoded, y_temp_encoded, y_train_one_hot, y_temp_one_hot = train_test_split(\n",
    "            images, labels_encoded, labels_one_hot, test_size=0.2, random_state=42, stratify=labels_encoded)\n",
    "        X_val, X_test, y_val_encoded, y_test_encoded, y_val_one_hot, y_test_one_hot = train_test_split(\n",
    "            X_temp, y_temp_encoded, y_temp_one_hot, test_size=0.5, random_state=42, stratify=y_temp_encoded)\n",
    "\n",
    "        return (X_train, y_train_encoded, y_train_one_hot), \\\n",
    "               (X_val, y_val_encoded, y_val_one_hot), \\\n",
    "               (X_test, y_test_encoded, y_test_one_hot)\n",
    "\n",
    "# Instantiate the DatasetLoader and load the data\n",
    "data_loader = DatasetLoader('/Users/valeriagarcia/Desktop/ESS569_Snowflake_Classification/PHIPS_CrystalHabitAI_Dataset.nc')\n",
    "images, labels, temps = data_loader.load_data()\n",
    "images, labels_one_hot, labels_encoded, num_classes, label_encoder = data_loader.preprocess_data(images, labels)\n",
    "(X_train, y_train_encoded, y_train_one_hot), \\\n",
    "(X_val, y_val_encoded, y_val_one_hot), \\\n",
    "(X_test, y_test_encoded, y_test_one_hot) = data_loader.split_data(images, labels_encoded, labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Data Augmentation\n",
    "##### Here, we create a data augmentation generator (`train_datagen`) for the training data that applies random transformations—including rotations up to 20 degrees, horizontal and vertical shifts up to 10% of the image size, horizontal and vertical flips, zooms up to 10%—to enhance the diversity of the dataset during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0,  # Images are already normalized\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# No augmentation for validation and test data, only rescaling\n",
    "val_datagen = ImageDataGenerator(rescale=1.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train_one_hot, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val_one_hot, batch_size=32)\n",
    "test_generator = test_datagen.flow(X_test, y_test_one_hot, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Physics-Informed Loss Function with Probabilistic Class Likelihoods\n",
    "\n",
    "##### In the cloud microphysics community, it is well-understood from laboratory studies that different ice crystal habits have a tendency to grow within a specific range of temperatures and relative humidity conditions. An example of the different temperature regimes is provided in Varcie et al. 2024:\n",
    "* *polycrystalline growth layer* (growth of polycrstals) -  may occur when the ambient temperature is below -18˚C\n",
    "* *dendritic growth layer* (growth of dendrites) - may occur when temperature is warmer than or equal to -18˚C and less than or equal to -12˚C\n",
    "* *plate growth layer* (growth of plates) - may occur where temperature is warmer than -12˚C and less than -8˚C\n",
    "* *needle growth layer* (growth of needles) - may occur where temperatures are warmer than or equal to -8˚C and less than -3˚C\n",
    "\n",
    "##### As our dataset only contains temperature in the metadata, we will focus on leveraging temperature and the temperature regimes above to create a custom loss function. Note the above temperature ranges refer to temperature layers over which certain ice crystals *may* grow, assuming other conditions, such as high ice/water supersaturations, are met. Moreover, particles that growth at cooler temperatures may still be observed at warmer temperatures due to sedimentation of the particles. \n",
    "\n",
    "##### Objective: Incorporate temperature-dependent class probabilities into the loss function to guide the model based on physical principles while allowing for natural variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: aggregate\n",
      "Class 1: bullet_rosette\n",
      "Class 2: capped_column\n",
      "Class 3: column\n",
      "Class 4: dendrite\n",
      "Class 5: graupel\n",
      "Class 6: needle\n",
      "Class 7: plate\n",
      "Class 8: polycrystal\n",
      "Class 9: side_plane\n",
      "Class 10: tiny\n",
      "\n",
      "Class 0: Mean Temp = -11.28, Std Temp = 4.97\n",
      "Class 1: All temperature values are NaN. Cannot compute mean and std.\n",
      "Class 2: Mean Temp = -11.40, Std Temp = 2.89\n",
      "Class 3: Mean Temp = -13.08, Std Temp = 4.77\n",
      "Class 4: Mean Temp = -14.17, Std Temp = 2.99\n",
      "Class 5: Mean Temp = -11.17, Std Temp = 4.74\n",
      "Class 6: Mean Temp = -3.14, Std Temp = 1.18\n",
      "Class 7: Mean Temp = -9.33, Std Temp = 4.09\n",
      "Class 8: Mean Temp = -13.55, Std Temp = 4.28\n",
      "Class 9: Mean Temp = -9.21, Std Temp = 4.76\n",
      "Class 10: Mean Temp = -8.36, Std Temp = 3.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/d4xxsc2518zggw88z1b9s5rh0000gn/T/ipykernel_16240/1332601326.py:30: RuntimeWarning: Mean of empty slice\n",
      "  mean_temp = np.nanmean(temps_)\n",
      "/Users/valeriagarcia/opt/anaconda3/envs/snowflake_classific/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "#### Create a mapping from class labels to their corresponding temperatures ####\n",
    "\n",
    "# Get unique class labels\n",
    "unique_classes = np.unique(labels_encoded)\n",
    "\n",
    "# Initialize a dictionary to hold temperatures for each class\n",
    "class_temperatures = {class_idx: [] for class_idx in unique_classes}\n",
    "\n",
    "# Populate the dictionary\n",
    "for idx, class_idx in enumerate(labels_encoded):\n",
    "    temp = temps[idx]\n",
    "    class_temperatures[class_idx].append(temp)\n",
    "\n",
    "# Print the mapping of integer labels to original labels\n",
    "for class_idx, class_label in enumerate(label_encoder.classes_):\n",
    "    print(f\"Class {class_idx}: {class_label}\")\n",
    "\n",
    "print()\n",
    "\n",
    "#### Calculate the mean and standard deviation for the temperatures in each class ####\n",
    "\n",
    "# Initialize the dictionary to hold temperature statistics for each class\n",
    "class_temperature_stats = {}\n",
    "\n",
    "# Compute mean and standard deviation for each class, ignoring NaNs\n",
    "for class_idx in unique_classes:\n",
    "    temps_ = np.array(class_temperatures[class_idx])\n",
    "    \n",
    "    # Compute mean and standard deviation while ignoring NaNs\n",
    "    mean_temp = np.nanmean(temps_)\n",
    "    std_temp = np.nanstd(temps_)\n",
    "    \n",
    "    # Handle case where all temps are NaN\n",
    "    if np.isnan(mean_temp) or np.isnan(std_temp):\n",
    "        print(f\"Class {class_idx}: All temperature values are NaN. Cannot compute mean and std.\")\n",
    "        class_temperature_stats[class_idx] = {'mean': np.nan, 'std': np.nan}\n",
    "    else:\n",
    "        class_temperature_stats[class_idx] = {'mean': mean_temp, 'std': std_temp}\n",
    "        print(f\"Class {class_idx}: Mean Temp = {mean_temp:.2f}, Std Temp = {std_temp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_expected_probs() function calculates the expected class probabilities for each sample in a batch based on its temperature, using Gaussian distributions derived from the class temperature statistics.\n",
    "# This function will be called within the physics-informed loss function to obtain the expected probabilities based on temperature, which are then used to compute the physics term (e.g., KL divergence).\n",
    "\n",
    "def get_expected_probs(temperature_batch, num_classes):\n",
    "    # Initialize expected probabilities array\n",
    "    expected_probs = np.zeros((len(temperature_batch), num_classes), dtype=np.float32)\n",
    "    \n",
    "    for i, temp in enumerate(temperature_batch):\n",
    "        total_prob = 0.0\n",
    "        probs = np.zeros(num_classes, dtype=np.float32)\n",
    "        \n",
    "        # Handle NaN temperatures by assigning uniform probabilities\n",
    "        if np.isnan(temp):\n",
    "            # Assign uniform probability if temperature is NaN\n",
    "            probs[:] = 1.0 / num_classes\n",
    "        else:\n",
    "            for class_idx in range(num_classes):\n",
    "                mean = class_temperature_stats[class_idx]['mean']\n",
    "                std = class_temperature_stats[class_idx]['std']\n",
    "                \n",
    "                # Handle classes with NaN mean or std by assigning uniform probability\n",
    "                if np.isnan(mean) or np.isnan(std):\n",
    "                    prob = 1.0 / num_classes\n",
    "                else:\n",
    "                    # Gaussian probability density function\n",
    "                    prob = np.exp(-0.5 * ((temp - mean) / std) ** 2) / (std * np.sqrt(2 * np.pi))\n",
    "                probs[class_idx] = prob\n",
    "                total_prob += prob\n",
    "            \n",
    "            # Normalize probabilities to sum to 1\n",
    "            if total_prob > 0:\n",
    "                probs /= total_prob\n",
    "            else:\n",
    "                # If total_prob is zero (unlikely), assign uniform probabilities\n",
    "                probs[:] = 1.0 / num_classes\n",
    "        \n",
    "        expected_probs[i] = probs\n",
    "    \n",
    "    return expected_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The temperature statistics are all NaN for the bullet rosette category (class 1)\n",
    "# The physics-informed loss function will be modified to exclude classes with missing temperature data (e.g., Class 1) from the physics term.\n",
    "\n",
    "# Define the physics-informed loss function\n",
    "def physics_informed_loss(y_true, y_pred, temperature):\n",
    "    # Standard categorical cross-entropy loss\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    loss = cce(y_true, y_pred)\n",
    "    \n",
    "    # Identify samples not belonging to classes with missing temperature stats\n",
    "    class_indices = tf.argmax(y_true, axis=1)\n",
    "    valid_class_mask = tf.constant([\n",
    "        not np.isnan(class_temperature_stats[i]['mean']) for i in range(num_classes)\n",
    "    ], dtype=tf.bool)\n",
    "    sample_mask = tf.gather(valid_class_mask, class_indices)\n",
    "    sample_mask = tf.cast(sample_mask, tf.float32)\n",
    "    \n",
    "    # Compute expected probabilities based on temperature\n",
    "    expected_probs = tf.numpy_function(\n",
    "        func=get_expected_probs,\n",
    "        inp=[temperature, num_classes],\n",
    "        Tout=tf.float32\n",
    "    )\n",
    "    \n",
    "    # Compute the physics term (KL divergence)\n",
    "    kl_divergence = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    physics_term = kl_divergence(expected_probs, y_pred)\n",
    "    \n",
    "    # Apply the mask to exclude invalid samples\n",
    "    physics_term = physics_term * sample_mask\n",
    "    \n",
    "    # Compute mean physics term over valid samples\n",
    "    total_valid_samples = tf.reduce_sum(sample_mask) + 1e-7  # Avoid division by zero\n",
    "    physics_term = tf.reduce_sum(physics_term) / total_valid_samples\n",
    "    \n",
    "    # Total loss with weighting factor\n",
    "    lambda_weight = 0.1  # Adjust as needed\n",
    "    total_loss = loss + lambda_weight * physics_term\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Model Definitions\n",
    "\n",
    "##### Here, we will define the DL models to be used (e.g., VGG16 with fine-tuning, InceptionV3, CRNN with Attention) with necessary adjustments to accept temperature data where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. VGG16 with Fine-Tuning\n",
    "**Implementation details:**\n",
    "* Pre-trained VGG16 Model: Utilize the VGG16 model pre-trained on ImageNet.\n",
    "* Input Adjustments: Convert grayscale images to RGB by repeating the single channel three times.\n",
    "* Output Layer: Adjust the final dense layer to match the number of classes.\n",
    "* Temperature Handling: Temperature data is not fed into the model but provided to the loss function during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Model:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape  # Shape: (height, width, channels)\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input layer for images\n",
    "        inputs = Input(shape=self.input_shape, name='image_input')\n",
    "\n",
    "        # Convert grayscale to RGB by repeating channels\n",
    "        x = Concatenate(axis=-1)([inputs, inputs, inputs])  # Shape: (height, width, 3)\n",
    "\n",
    "        # Load pre-trained VGG16 model without the top layer and wiht pre-trained weights\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_tensor=x)\n",
    "\n",
    "        # Freeze base model layers for initial training (to keep pre-trained features during training)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add custom layers on top (more specifically, adds GlobalAveragePooling2D, a dense layer with 256 units and ReLU activation, and an output layer matching the number of classes with softmax activation)\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        outputs = Dense(self.num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "        # Construct the model\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='VGG16Model')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def compile_model(self):\n",
    "        # Compilation will be handled in the training step using a custom training loop\n",
    "        pass  # No action needed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. InceptionV3\n",
    "**Implementation details:**\n",
    "* Pre-trained InceptionV3 Model: Utilize the InceptionV3 model pre-trained on ImageNet.\n",
    "* Input Adjustments: Convert grayscale images to RGB. Also resize images to the expected input size for InceptionV3 (e.g., 299x299).\n",
    "* Output Layer: Adjust the final dense layer to match the number of classes.\n",
    "* Temperature Handling: Temperature data is not fed into the model but provided to the loss function during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3Model:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape  # Original image shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input layer for images\n",
    "        inputs = Input(shape=self.input_shape, name='image_input')\n",
    "\n",
    "        # Resize images to 299x299 as expected by InceptionV3\n",
    "        x = Resizing(299, 299)(inputs)\n",
    "\n",
    "        # Convert grayscale to RGB\n",
    "        x = Concatenate(axis=-1)([x, x, x])  # Shape: (299, 299, 3)\n",
    "\n",
    "        # Load pre-trained InceptionV3 model without the top layer\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=x)\n",
    "\n",
    "        # Freeze base model layers for initial training\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add custom layers on top\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        outputs = Dense(self.num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "        # Construct the model\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='InceptionV3Model')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def compile_model(self):\n",
    "        # Compilation will be handled during training with the custom loss\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. CRNN with Attention Mechanism\n",
    "**Implementation details:**\n",
    "* Convolutional Layers: Extract spatial features from images.\n",
    "* Recurrent Layers (LSTM): Capture sequential dependencies in the extracted features.\n",
    "* Attention Mechanism: Enhance the model's focus on relevant features.\n",
    "* Input Adjustments: Use the grayscale images directly.\n",
    "* Output Layer: Adjust the final dense layer to match the number of classes.\n",
    "* Temperature Handling: Temperature data is not fed into the model but provided to the loss function during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNNModel:\n",
    "    def __init__(self, input_shape, num_classes, lstm_units=64):\n",
    "        self.input_shape = input_shape  # Shape: (height, width, channels)\n",
    "        self.num_classes = num_classes\n",
    "        self.lstm_units = lstm_units\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input layer for images\n",
    "        inputs = Input(shape=self.input_shape, name='image_input')\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        # Prepare data for LSTM\n",
    "        shape = x.shape\n",
    "        x = Reshape((shape[1] * shape[2], shape[3]))(x)  # Shape: (batch_size, timesteps, features)\n",
    "\n",
    "        # LSTM layer\n",
    "        x = LSTM(self.lstm_units, return_sequences=True)(x)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention = Dense(1, activation='tanh')(x)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(self.lstm_units)(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "        x = Multiply()([x, attention])\n",
    "        x = Lambda(lambda xin: K.sum(xin, axis=1))(x)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = Dense(self.num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "        # Construct the model\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='CRNNModel')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def compile_model(self):\n",
    "        # Compilation will be handled during training with the custom loss\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impacts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
